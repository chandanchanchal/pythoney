/mnt/delta/bronze/employees
/mnt/delta/silver/employees
/mnt/delta/gold/employee_metrics

dbutils.fs.mkdirs("/mnt/delta/bronze/employees")


###########--------Silver---layer---creation--#################

raw_data = [
    (1, "Alice", "IT", "70000"),
    (2, "Bob", "HR", "65000"),
    (3, "Charlie", "IT", None),
    (4, "David", "Finance", "Eighty Thousand")
]

columns = ["emp_id", "name", "dept", "salary"]

raw_df = spark.createDataFrame(raw_data, columns)

raw_df.write \
  .format("delta") \
  .mode("append") \
  .save("/tmp/delta/bronze/employees")

bronze_df = spark.read.format("delta") \
    .load("/tmp/delta/bronze/employees")

from pyspark.sql.functions import col, when

silver_df = bronze_df \
    .withColumn("salary",
        when(col("salary").cast("int").isNotNull(),
             col("salary").cast("int"))
        .otherwise(None)
    ) \
    .filter(col("salary").isNotNull())

silver_df.write \
  .format("delta") \
  .mode("overwrite") \
  .save("/tmp/delta/silver/employees")

